{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cabfb51",
   "metadata": {},
   "source": [
    "## How to run the script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65a3017",
   "metadata": {},
   "source": [
    "Don't need to do anything, just press run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e2c493",
   "metadata": {},
   "source": [
    "## Purpose of the script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a1dbcd",
   "metadata": {},
   "source": [
    "In this script we're looking at the trainning delivered from 1st April 2022 for the work group sets we've made recommendations for "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e1e28",
   "metadata": {},
   "source": [
    "## 1. Get all file paths and read files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c42b55",
   "metadata": {},
   "source": [
    "#### 1.A. Import relavent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd1ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x) # Supress scientific notation\n",
    "import numpy as np\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import os\n",
    "import pyodbc\n",
    "from io import StringIO, BytesIO\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d95ee",
   "metadata": {},
   "source": [
    "#### 1.B. Define connections to SQL tables and Azure Storage blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcd8a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the connection to SQL database\n",
    "#conn = pyodbc.connect( # SQL server\n",
    "                       # name of SQL data base\n",
    "                        # UID =\n",
    "                       # Password\n",
    "#                      ) # databasename\n",
    "\n",
    "# To connect to Azure devp envirnoment                        \n",
    "#STORAGEACCOUNTURL= ''\n",
    "#STORAGEACCOUNTKEY= ''\n",
    "#CONTAINERNAME= ''\n",
    "#blob_service_client_instance_devp = BlobServiceClient(account_url=STORAGEACCOUNTURL, credential=STORAGEACCOUNTKEY)\n",
    "\n",
    "# To connect to Azure test envirnoment                        \n",
    "#STORAGEACCOUNTURL= ''\n",
    "#STORAGEACCOUNTKEY= ''\n",
    "#CONTAINERNAME= ''\n",
    "#blob_service_client_instance_devp = BlobServiceClient(account_url=STORAGEACCOUNTURL, credential=STORAGEACCOUNTKEY)\n",
    "\n",
    "# To connect to Azure staging envirnoment                        \n",
    "#STORAGEACCOUNTURL= ''\n",
    "#STORAGEACCOUNTKEY= ''\n",
    "#CONTAINERNAME= ''\n",
    "#blob_service_client_instance_devp = BlobServiceClient(account_url=STORAGEACCOUNTURL, credential=STORAGEACCOUNTKEY)\n",
    "\n",
    "# To connect to Azure prod envirnoment                        \n",
    "#STORAGEACCOUNTURL= ''\n",
    "#STORAGEACCOUNTKEY= ''\n",
    "#CONTAINERNAME= ''\n",
    "#blob_service_client_instance_devp = BlobServiceClient(account_url=STORAGEACCOUNTURL, credential=STORAGEACCOUNTKEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2852881a",
   "metadata": {},
   "source": [
    "#### 1.C. Define all the Functions used in the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b58d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a funtion to read csv files directly from azure data storage\n",
    "def download_csv(BLOBNAME):\n",
    "    blob_client_instance = blob_service_client_instance_devp.get_blob_client(CONTAINERNAME, BLOBNAME, snapshot=None)\n",
    "    blob_data = blob_client_instance.download_blob()\n",
    "    with BytesIO() as f:\n",
    "        blob_data.readinto(f)\n",
    "        f.seek(0)\n",
    "        data = pd.read_csv(f)   \n",
    "    return data\n",
    "\n",
    "# Define a funtion to read excel files directly from azure data storage\n",
    "def download_excel(BLOBNAME):\n",
    "    blob_client_instance = blob_service_client_instance_devp.get_blob_client(CONTAINERNAME, BLOBNAME, snapshot=None)\n",
    "    blob_data = blob_client_instance.download_blob()\n",
    "    with BytesIO() as f:\n",
    "        blob_data.readinto(f)\n",
    "        f.seek(0)\n",
    "        data = pd.read_excel(f)   \n",
    "    return data\n",
    "\n",
    "# Rename columns\n",
    "def rename_column(table_name):\n",
    "    table_name.columns = table_name.columns.str.replace(' ', '')\n",
    "    table_name.columns = table_name.columns.str.lower()\n",
    "\n",
    "# Save csv files and upload to azure blob storage\n",
    "def save_outputs_azure_blobs(output_name1,output_name2,output_name3,azure_environment):\n",
    "    output_name1.to_csv(output_name2, index = False)\n",
    "    # Create a blob client using the local file name as the name for the blob\n",
    "    blob_client = azure_environment.get_blob_client(container='input', blob='static/benefitsBaseline/{tmp2}/{tmp3}'.format(tmp2=output_name3,tmp3=output_name2))\n",
    "    # Upload the created file\n",
    "    with open(output_name2, \"rb\") as data:\n",
    "        blob_client.upload_blob(data,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1155c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendations LOSC (AZURE BLOB)\n",
    "losc_recom = download_csv('static/benefitsBaseline/recommendations_sep2021_fix_June2022/losc_benefits_and_recommendations_2021_dcs_MAX.csv')\n",
    "rename_column(losc_recom)\n",
    "\n",
    "# Recommendations FMS\n",
    "fms_recom = download_csv('static/benefitsBaseline/recommendations_sep2021_fix_June2022/fms_benefits_and_recommendations_2021_dcs.csv')\n",
    "rename_column(fms_recom)\n",
    "\n",
    "# Recommendations Workbank\n",
    "workbank_recom = download_csv('static/benefitsBaseline/recommendations_sep2021_fix_June2022/workbank_benefits_and_recommendations_2021_dcs.csv')\n",
    "rename_column(workbank_recom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c68f41",
   "metadata": {},
   "source": [
    "#### 1.D. Read the paths to all files/download blobs/read SQL tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6576cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINNING DEMAND (SQL)\n",
    "trainning_demand  = pd.read_sql_query('''select * from [dbo].[trainingDemand]''', conn)\n",
    "rename_column(trainning_demand)\n",
    "\n",
    "# ORGPLUS PRE INTERVENTION (SQL)\n",
    "ORG_DATA_pre= pd.read_sql_query('''select * from [dbo].[orgPlusBaseline]''', conn)\n",
    "rename_column(ORG_DATA_pre)\n",
    "# ORGPLUS POST INTERVENTION (SQL)\n",
    "ORG_DATA_post= pd.read_sql_query('''select * from [dbo].[orgPlus]''', conn)\n",
    "rename_column(ORG_DATA_post)\n",
    "\n",
    "# WGS PRE INTERVENTION (SQL)\n",
    "workgroup_data_pre= pd.read_sql_query('''select * from [dbo].[workGroupSetBaseline]''', conn)\n",
    "rename_column(workgroup_data_pre)\n",
    "# WGS POST INTERVENTION (SQL)\n",
    "workgroup_data_post= pd.read_sql_query('''select * from [dbo].[workGroupSet]''', conn)\n",
    "rename_column(workgroup_data_post)\n",
    "\n",
    "# COURSE LIST (SQL)\n",
    "course_list= pd.read_sql_query('''select * from [dbo].[courseList]''', conn)\n",
    "rename_column(course_list)\n",
    "\n",
    "# Recommendations LOSC (AZURE BLOB)\n",
    "losc_recom = download_csv('static/benefitsBaseline/recommendations_sep2021_fix_June2022/losc_benefits_and_recommendations_2021_dcs_MAX.csv')\n",
    "rename_column(losc_recom)\n",
    "\n",
    "# Recommendations FMS\n",
    "fms_recom = download_csv('static/benefitsBaseline/recommendations_sep2021_fix_June2022/fms_benefits_and_recommendations_2021_dcs.csv')\n",
    "rename_column(fms_recom)\n",
    "\n",
    "# Recommendations Workbank\n",
    "workbank_recom = download_csv('static/benefitsBaseline/recommendations_sep2021_fix_June2022/workbank_benefits_and_recommendations_2021_dcs.csv')\n",
    "rename_column(workbank_recom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4e2b1d",
   "metadata": {},
   "source": [
    "## 2. Pre Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb15035",
   "metadata": {},
   "source": [
    "#### 2.A. Trainning demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41d21342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place Booked                                 24958\n",
      "Completed                                    16151\n",
      "Passed                                       12123\n",
      "Cancelled - replaced                          3421\n",
      "Attended                                      3321\n",
      "Cancelled - not required                      2603\n",
      "Cancelled - date or location not suitable     2498\n",
      "Booked - No Show                              2488\n",
      "Cancelled - by training provider              1212\n",
      "Cancelled - annual leave                      1046\n",
      "Cancelled - illness or family issue            673\n",
      "Cancelled - required at work                   603\n",
      "Cancelled - no charge                          598\n",
      "Cancelled - not eligible                       595\n",
      "Failed                                         480\n",
      "Cancelled - By Training Admin                  300\n",
      "Attended - Appreciation                        239\n",
      "Cancelled - other training commitments         239\n",
      "Attended - Did Not Complete                    197\n",
      "Partial Pass                                   153\n",
      "Place Booked - No JI                            80\n",
      "Cancelled - charge                              35\n",
      "Placed Booked - Appreciation                     9\n",
      "Attended -  Did Not Complete                     8\n",
      "Cancelled - course is full                       5\n",
      "Cancelled - due to weather conditions            5\n",
      "Placed - Pending                                 2\n",
      "Cancelled - Unapproved                           1\n",
      "Name: enrollstatusbreakdown, dtype: int64\n",
      "74043\n",
      "Completed    16151\n",
      "Passed       12123\n",
      "Attended      3321\n",
      "Name: enrollstatusbreakdown, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Trainning demand drop empty columns\n",
    "trainning_demand.dropna(how='all', axis=1, inplace=True)\n",
    "\n",
    "## Filter out for trainning delievered\n",
    "print(trainning_demand['enrollstatusbreakdown'].value_counts())\n",
    "print(len(trainning_demand['enrollstatusbreakdown']))\n",
    "\n",
    "trainning_demand = trainning_demand[['coursecategory','coursetitle','employeenumber','deliveryunit',\n",
    "                                     'enrollstatusbreakdown','ced','csd','orgcostcentre','periodstart','startyear','periodend',\n",
    "                                     'endyear','period']]\n",
    "len(trainning_demand)\n",
    "\n",
    "# Only keep trainnig where they've passed\n",
    "trainning_demand = trainning_demand.loc[trainning_demand['enrollstatusbreakdown'].isin(['Completed', 'Passed', 'Attended'])]\n",
    "print(trainning_demand['enrollstatusbreakdown'].value_counts())\n",
    "len(trainning_demand)\n",
    "\n",
    "# Only keep trainning delivered after 1st April 2022\n",
    "trainning_demand['csd'] = pd.to_datetime(trainning_demand['csd'], format='%Y-%m-%d')\n",
    "trainning_demand_filter = trainning_demand.loc[(trainning_demand['csd'] >= '2022-04-01')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7380b3c8",
   "metadata": {},
   "source": [
    "#### 2.B. Orgplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "500cf531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42883"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OrgPlus\n",
    "ORG_DATA_pre = ORG_DATA_pre.loc[~ORG_DATA_pre['employeenumber'].isna()]\n",
    "ORG_DATA_pre['employeenumber'] = ORG_DATA_pre['employeenumber'].astype(int)\n",
    "# Drop all columns which are blanks\n",
    "ORG_DATA_pre.dropna(how='all', axis=1, inplace=True)\n",
    "print(len(ORG_DATA_pre))\n",
    "\n",
    "# OrgPlus\n",
    "ORG_DATA_post = ORG_DATA_post.loc[~ORG_DATA_post['employeenumber'].isna()]\n",
    "ORG_DATA_post['employeenumber'] = ORG_DATA_post['employeenumber'].astype(int)\n",
    "# Drop all columns which are blanks\n",
    "ORG_DATA_post.dropna(how='all', axis=1, inplace=True)\n",
    "len(ORG_DATA_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5264e6bd",
   "metadata": {},
   "source": [
    "#### 2.D. Course List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a92e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Course list\n",
    "course_list['coursetitle'].value_counts()\n",
    "\n",
    "# drop this as it is not important \n",
    "course_list = course_list[course_list['competencealias'] != 'LKT EL']\n",
    "\n",
    "# Anywhere it says any variation of LKT - chnage it to LKT \n",
    "course_list['competencealias']= course_list['competencealias'].map(lambda x: \"LKT\" if \"LKT\" in x else x)\n",
    "\n",
    "course_list = course_list[['typemeaning', 'competencealias', 'competence','coursetitle', 'proficiencylevel']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff38540",
   "metadata": {},
   "source": [
    "#### 2.E. Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f99e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendations LOSC\n",
    "losc_recom = losc_recom[['deliveryunit', 'workgroupset', 'competencealias',\n",
    "       'parentcompetence', 'recommendednumberofpeopletotrain',\n",
    "       'losccostbenefit(£)', 'competencedescription']]\n",
    "\n",
    "# Recommendations FMS\n",
    "fms_recom = fms_recom[['deliveryunit', 'workgroupset', 'competencealias','recommendednumberofpeopletotrain',\n",
    "       'benefit(delayminutes)', 'competencedescription']]\n",
    "# Recommendations Workbank\n",
    "workbank_recom = workbank_recom[['deliveryunit', 'workgroupset', 'competencealias','recommendednumberofpeopletotrain',\n",
    "       'workbankbenefit(backloghrs)', 'competencedescription']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7638ec5e",
   "metadata": {},
   "source": [
    "## 3. Extract Team Size from OrgPlus, Work group set info "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c0e682",
   "metadata": {},
   "source": [
    "#### 3.A. WGS + Orgplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d1f4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orgplus_wgs_merge(table_name1,table_name2):\n",
    "    OrgPlus_WGS = pd.merge(table_name1,\n",
    "                           table_name2[['routelookup','smengineerupn', 'workgroupset', 'masterdeliveryunit']],\n",
    "                           left_on='parentupn', right_on='smengineerupn', how='left')\n",
    "\n",
    "    # Drop all records with no parent UPN OrgPlus_WGS we can't link those to a Delivery Unit\n",
    "    OrgPlus_WGS = OrgPlus_WGS.loc[~OrgPlus_WGS['smengineerupn'].isna()].reset_index(drop=True)\n",
    "\n",
    "    OrgPlus_WGS = OrgPlus_WGS[['costcentre','routelookup',\n",
    "        'employeenumber','parentupn', 'upn', 'smengineerupn', 'workgroupset',\n",
    "        'masterdeliveryunit']]\n",
    "\n",
    "    return OrgPlus_WGS\n",
    "\n",
    "\n",
    "OrgPlus_WGS_pre = orgplus_wgs_merge(ORG_DATA_pre,workgroup_data_pre)\n",
    "OrgPlus_WGS_post = orgplus_wgs_merge(ORG_DATA_post,workgroup_data_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdf044d",
   "metadata": {},
   "source": [
    "#### 3.B. Team Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85ef9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_team_size(table_name):\n",
    "    Team_size = table_name.groupby(['masterdeliveryunit', 'workgroupset'])['employeenumber'].nunique().reset_index()\n",
    "    Team_size.rename(columns={'employeenumber':'Team Size'},inplace=True)\n",
    "    return Team_size\n",
    "team_size_pre = calculate_team_size(OrgPlus_WGS_pre)\n",
    "team_size_post = calculate_team_size(OrgPlus_WGS_post)\n",
    "\n",
    "# save output as csv and upload to azure blob storage containers\n",
    "save_outputs_azure_blobs(team_size_pre,'team_size_PreInter.csv','teamSize',blob_service_client_instance_devp)\n",
    "save_outputs_azure_blobs(team_size_post,'team_size_PostInter.csv','teamSize',blob_service_client_instance_devp)\n",
    "\n",
    "save_outputs_azure_blobs(team_size_pre,'team_size_PreInter.csv','teamSize',blob_service_client_instance_test)\n",
    "save_outputs_azure_blobs(team_size_post,'team_size_PostInter.csv','teamSize',blob_service_client_instance_test)\n",
    "\n",
    "save_outputs_azure_blobs(team_size_pre,'team_size_PreInter.csv','teamSize',blob_service_client_instance_prod)\n",
    "save_outputs_azure_blobs(team_size_post,'team_size_PostInter.csv','teamSize',blob_service_client_instance_prod)\n",
    "\n",
    "save_outputs_azure_blobs(team_size_pre,'team_size_PreInter.csv','teamSize',blob_service_client_instance_staging)\n",
    "save_outputs_azure_blobs(team_size_post,'team_size_PostInter.csv','teamSize',blob_service_client_instance_staging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5439d5",
   "metadata": {},
   "source": [
    "## 4. Merge trainning delivered with trainning recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a602ee",
   "metadata": {},
   "source": [
    "#### 4.A. Merge work group set info with trainning demand to assign employees to work group sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b88e5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2349"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge work group set info with trainning demand to assign employees to work group sets\n",
    "training_demand_orgplus_wgs = pd.merge(trainning_demand_filter,OrgPlus_WGS_post,how='left',\n",
    "                                       left_on=['employeenumber'], \n",
    "                                       right_on=['employeenumber'])\n",
    "training_demand_orgplus_wgs = training_demand_orgplus_wgs.loc[~training_demand_orgplus_wgs['workgroupset'].isna()].reset_index(drop=True)\n",
    "training_demand_orgplus_wgs['workgroupset'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ff61aa",
   "metadata": {},
   "source": [
    "#### 4.B. Merge recommendations with courses and trainning delivered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dccf0514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n",
      "254\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "# Merge losc recommendations with courses \n",
    "def trainning_delivered(table_name1):\n",
    "    recom_course = pd.merge(table_name1,course_list,how='left',\n",
    "                    left_on=['competencealias'],\n",
    "                    right_on=['competencealias'])\n",
    "    \n",
    "    recomen_course_trainning = pd.merge(training_demand_orgplus_wgs,recom_course,how='left',\n",
    "                                       left_on = ['coursetitle','workgroupset'],\n",
    "                                       right_on=['coursetitle','workgroupset'])\n",
    "    recomen_course_trainning = recomen_course_trainning.loc[~recomen_course_trainning['recommendednumberofpeopletotrain'].isna()].reset_index(drop=True)   \n",
    "    print(len(recomen_course_trainning))\n",
    "    return recomen_course_trainning\n",
    "\n",
    "workbank_recomen_course_trainning = trainning_delivered(workbank_recom)\n",
    "workbank_recomen_course_trainning = pd.DataFrame(workbank_recomen_course_trainning.groupby(['routelookup','workgroupset','masterdeliveryunit','coursetitle','competencealias','recommendednumberofpeopletotrain','workbankbenefit(backloghrs)'])['employeenumber'].count()).reset_index()\n",
    "\n",
    "fms_recomen_course_trainning = trainning_delivered(fms_recom)\n",
    "fms_recomen_course_trainning = pd.DataFrame(fms_recomen_course_trainning.groupby(['routelookup','workgroupset','masterdeliveryunit','coursetitle','competencealias','recommendednumberofpeopletotrain','benefit(delayminutes)'])['employeenumber'].count()).reset_index()\n",
    "\n",
    "losc_recomen_course_trainning = trainning_delivered(losc_recom)\n",
    "losc_recomen_course_trainning = pd.DataFrame(losc_recomen_course_trainning.groupby(['routelookup','workgroupset','masterdeliveryunit','coursetitle','competencealias','recommendednumberofpeopletotrain','losccostbenefit(£)'])['employeenumber'].count()).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c87747",
   "metadata": {},
   "source": [
    "#### 4.C Save outputs to Azure blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1356c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save outputs as csv and read to azure blob storage containers\n",
    "save_outputs_azure_blobs(workbank_recomen_course_trainning,'workbank_recomen_course_trainning.csv','trainning_delivered_recommendations',blob_service_client_instance_devp)\n",
    "save_outputs_azure_blobs(fms_recomen_course_trainning,'fms_recomen_course_trainning.csv','trainning_delivered_recommendations',blob_service_client_instance_devp)\n",
    "save_outputs_azure_blobs(losc_recomen_course_trainning,'losc_recomen_course_trainning.csv','trainning_delivered_recommendations',blob_service_client_instance_devp)\n",
    "\n",
    "# Save outputs as csv and read to azure blob storage containers\n",
    "save_outputs_azure_blobs(workbank_recomen_course_trainning,'workbank_recomen_course_trainning.csv','trainning_delivered_recommendations',blob_service_client_instance_test)\n",
    "save_outputs_azure_blobs(fms_recomen_course_trainning,'fms_recomen_course_trainning.csv','trainning_delivered_recommendations',blob_service_client_instance_test)\n",
    "save_outputs_azure_blobs(losc_recomen_course_trainning,'losc_recomen_course_trainning.csv','trainning_delivered_recommendations',blob_service_client_instance_test)\n",
    "\n",
    "# Save outputs as csv and read to azure blob storage containers\n",
    "save_outputs_azure_blobs(workbank_recomen_course_trainning,'workbank_recomen_course_trainning.csv','trainning_delivered_recommendations',blob_service_client_instance_prod)\n",
    "save_outputs_azure_blobs(fms_recomen_course_trainning,'fms_recomen_course_trainning.csv','trainning_delivered_recommendations',blob_service_client_instance_prod)\n",
    "save_outputs_azure_blobs(losc_recomen_course_trainning,'losc_recomen_course_trainning.csv','trainning_delivered_recommendations',blob_service_client_instance_prod)\n",
    "\n",
    "# Save outputs as csv and read to azure blob storage containers\n",
    "save_outputs_azure_blobs(workbank_recomen_course_trainning,'workbank_recomen_course_trainning.csv','trainning_delivered_recommendations',blob_service_client_instance_staging)\n",
    "save_outputs_azure_blobs(fms_recomen_course_trainning,'fms_recomen_course_trainning.csv','trainning_delivered_recommendations',blob_service_client_instance_staging)\n",
    "save_outputs_azure_blobs(losc_recomen_course_trainning,'losc_recomen_course_trainning.csv','trainning_delivered_recommendations',blob_service_client_instance_staging)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "db48200f30cd3676e4593a3cdb043b1791a744e8ef38beb98db8b8f9b8797541"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
